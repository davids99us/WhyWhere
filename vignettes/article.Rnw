\documentclass{article}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{float}
\floatplacement{figure}{H}
\usepackage{lineno}
\linenumbers
\usepackage{fancyhdr}
%-------------------------------------------------------------------------
% take the % away on next line to produce the final camera-ready version
% Be sure to remove \thispagestyle{fancy} as well after the \maketitle.
%\pagestyle{empty}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[CO, CE]{\texttt{-Manuscript Draft-}}
\setlength{\headheight}{2\baselineskip}
\renewcommand{\headrulewidth}{0pt}
 


%\VignetteIndexEntry{Using whywhere}
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}} 
\usepackage{listings}
\lstdefinestyle{myCustomMatlabStyle}{
  language=R,
  stepnumber=1,
  basicstyle=\footnotesize,  
  tabsize=4,
  showspaces=false,
  showstringspaces=false
}
\DeclareTextFontCommand{\emph}{\bfseries}



\title{\texttt{whywhere:} An R package for ecological niche modelling on environmental big data}
\author{David R.B. Stockwell\footnote{All correspondence to be addressed to the author at david.r.stockwell@cqu.edu.au, Adjunct Researcher at Central Queensland University.}}
\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle
\date
\thispagestyle{fancy}
\begin{abstract}
This package is an R implemention of the \texttt{WhyWhere} data mining algorithm \cite{Stockwell:2006xt}. Developed for biodiversity modelling with big data issues in mind, the approach is simple and rigorous, efficient to compute, and provides accuracy equal to the best alternative approaches.  It represents the way forward in utilize large spatial environmental data sets in a robust predictive and explanatory capacity.  
\end{abstract}

\section{Introduction} \label{sec:intro}

Niche modelling consists of developing models of environmental relationships from sparce point occurrence data such as sightings, museum records or other opportunisitc sources, and projecting these models into the 2D surface to produce a continuous map of the suitability of environments for the species.  Such maps can then be used for a range of conservation purposes.

The geographic data sets used in niche modelling are diverse: characterised by a large number of themes, local or global coverag, and coarse to fine scales of resolution.  As the size and availability of data sets expand there is a need to reexamine traditional approaches to data analysis and redesign the algorithms where necessary.  A number of issues arise in developing a more streamlined, automated data modelling process:

\begin{enumerate}
  \item Memory limitations: Most models are developed on an intermediate data stage in a 'wide' file format, i.e. with variables in columns and locations in rows. This is an addition step.  All environmental data must be then be held in memory.  Here we consider an algorithm needs only one data set at a time and so also supports model development on streaming spatial datasets.
  \item Combining Variables: Higher dimensional models must first be coregistered in both projection and resolution before modelling. This adds additional processing. Either smaller data sets are enlarged which increases memory usage with duplicate cells, or larger data deleted which loses data.  An ideal method would utilise the data at its native projection and resolution.
  \item Mixed Types: Environmental data are either continuous (eg. temperature, rainfall) or categorical (eg. biome or soil type).  Ideally a model would integrate both types, but very few do.  
  \item Non-linear responses: The response of species to environment is generally 'humped' around an ideal the environment may even be multi-modal. Thus models must be at least quadratic or have multiple forms, which often needs to be specified prior to analysis.  An ideal method would be robust to non-linear response type. 
 \item Ecological interpretation: How does the structure of a  multi-dimensional model embody the ecology of the species?  Many model applications are based in other domains (eg. generalised linear model) without clear ecological interpretation.
\end{enumerate}

The guide is arranged as follows.  Section 2 describes background and related work on the criteria outlined above.  Section 3 describes the algorithm and section 4 reports the results on a well known dataset on two environmental data sets: one a small set of 9 prepared spatial layers, and another a large set of 1000 global data-sets.

\section{Related Work}

A work flow for species modeling using spatial data and presence only records was developed in the GARP system \cite{Stockwell:1999yg}.  Elements of this work flow such as random sampling of background points are now widely used.  A newly developed package for species modelling (eg. MaxEnt, Bioclim, Domain, GLM, GAM, and RandomForest) has been collated in R  \texttt{dismo}.  Other R packages have made this modelling more accessible, particularly the \texttt{raster} package for handling gridded spatial data \cite{Etten2012}.  The R implementation of WhyWhere utilises a new package called \texttt{data.table} for fast aggregation of large data \cite{Dowle2014}. 

\subsection{Arbitrary Distributions} 

In ecological niche theory a uni-modal or humped distribution of temperature or rainfall is the simplest viable distribution.  However, these distributions are often skewed and can also be multimodal.  In addition, many environmental variables are categorical variables such as soil and vegetation type.  One approach to robust modelling is to provide a range of potenital response types \cite{Phillips2007}.  

The approach in WhyWhere is segmentation -- to approximate non-linear responses with a discrete range.  Both continuous and categorical variables can be handled in the same framework. The original WhyWhere \cite{Stockwell:2006xt} used a color quantization algorithm similar to the GIF format.  The median cut algorithm attempts to assign equal numbers of points to a limited number of categories category \cite{Heckbert82} in the red, green, blue 3D space while retaining good appearance.  Quantisation in WhyWhere supported a 3 variable conjunctive model.  This is not a limitatio of the current version.

\subsection{Evaluating Models}

There are many ways to evaluate a model.  The categorical nature of the predicted variable (ie. presences and absences) determined from models outputs in the range of zero to one, (eg. probablistic prediction of a rule, logistic model or descision tree) against a categorical value (presence or absence).  The reciever operating curve (ROC) is widely used to compare such models, while the area under the curve of the receiver operating statistic (AUC) provides a single number estimate of model quality. 

The locations where the species occurs can be thought of as a sampling of the environmental space.  For a given data set - presence and absence - there is a count of values in the each category ($G1$).  There is a lesser count of values in the sample of presence points ($G2$).  The change in the distribution of counts from $G1$ to $G2$ indicates strength of the the response of the species to its environment - called the membership function $M$.  A membership function describes a fuzzy truth value as a function $f: \mathbb{R} \rightarrow [0,1]$ from a variable $V$ to the real unit interval $[0,1]$.  

\begin{equation}
M = G1/G2
\end{equation}

\begin{figure}[htbp]
\begin{center}
<<fig=T,echo=T,eval=T,png=FALSE, pdf=TRUE>>=
source("../R/ww2.R")
files <- list.files(path="/home/davids99us/data/dismo",pattern='grd', full.names=TRUE )
file <- paste(system.file(package="dismo"), '/ex/bradypus.csv',sep='')
Pres <- fread(file,  header=T,sep=",")
Pres$species=NULL
result=ww(Pres,files,plot=FALSE,multi=TRUE,trim=FALSE)
plot.ww(result)
@
\caption{\label{fig1} \texttt{WhyWhere} predicted distribution of the Bradypus data set.}
\end{center}
\end{figure}



Table~\ref{tab1} lists and example lookup table.  

<<echo=FALSE, eval=TRUE, results=tex>>=
source("../R/ww2.R")
xtable(result$lookup,caption="These are the results", label="tab1")
@


In any sense, $M$ is similar to the conditional probability of species being present given the environmental value falls in a category.  While many models attempt to represent the full probability using Bayes Theorem for example, the probability of the occurrence of a species $P(S)$ in opportunistic data is not well defined, and not generally of interest and dependent on season, search effort and other uncontrolled variables.  The membership function is a proportional relationship which is sufficient for AUC to compare models.  

\subsection{Single Variables}

The approach to evaluating the strength of the response in the original WhyWhere was significance with the Chi-squared test or a K-S test. However Chi2 doesn't work in evaluating the multivariate case, and there is another approach.

The output of the membership function for a single variable is vector of memberships for each location.  We can combine the membership vectors for two variables using a fuzzy AND to produce a new membership vector.  This can be evaluated with the AUC.  The AND, OR operators on probability are Zadeh operators:

\begin{equation}
AND: x \land y = min(f(x),f(y)) \\
OR: x \land y = max(f(x),f(y)) \\
\end{equation}

Using this approach eliminates the need to develop and apply a high dimensional model to data.

\subsection{Ecological Models}

The principle of Liebig's Law of the Minimum states that growth is controlled by the scarcest necessary resource.  This is logically a fuzzy conjunction of limiting factors -- a Zadeh AND.  Another law of ecology is Gauss's law of competitive exclusion.   This is a proposition that two species competing for the same resource cannot coexist at constant population, due to effect of slight advantages magnified over generations.  This is a fuzzy disjunction -- a Zadeh OR.  Thus fuzzy AND and OR can represent established ecological theory.

\section{WhyWhere Algorithm}

The inputs to \texttt{WhyWhere} are: a \texttt{data.table} with the longitude and latitude of known locations, and a list of environmental data files that may be read into the raster package.  Parameters include \emph{multi} for searching conjunctions of variables, \emph{split} for split testing on train and test sets, \emph{trim} to trim the spatial variables to the range of the location points.  

Figure~\ref{fig1}.A shows the highest rated variable in the Bradypus dataset, listed in panel Figure~\ref{fig1}.B. The lookup table is illustrated as a bar graph in Figure~\ref{fig1}.C with categorical ranges  listed on the \emph{x} axis.  The prior distribution ($G1$) is the blue line, and the distribution of presences ($G2$) is the dashed line.  The membership function is  the grey bars ($G1/G2$).  Note the almost uniform distribution of background classes due to the quantile cuts.  The predicted distribution of Bradypus is on Figure~\ref{fig1}.D.  

The current algorithm implements a beam search in which a conjunction of each new variable is tested with the best variable so far.  Alternaitve approaches to searching the space of conjunctions may be implemented in future.  

\lstset{basicstyle=\tiny,style=myCustomMatlabStyle,caption={Listing of the main algorithm},label=alg1}
\begin{lstlisting}[frame=single]
input locations  
input a mask file
prepare background points and combine with presence points
for all environmental files do
 develop membership function for file
 insert AUC and variable name into ordered result 
 test conjunct of this variable with best so far
 if result is better then insert into ordered result
output table of results
\end{lstlisting}

The mask file defines the geographic extent for the sampling the background data.  If absences are available then they need not be generated.  On looping through the environmental variables, a combination of the variables with the next best variables by applying the minimum of the item probability vectors and recalculating the AUC. It is possible to monitor the progress of \texttt{WhyWhere} with the plot option.  This plots out the best model sofar and prints out a list of the best models considered.  This protocol would also support a streaming work flow.

\section{Experiments}

\subsection{Local Data}

Data points for the feeding brown-throated three-toed sloth (\emph{Bradypus variegatus}) are documented and applied to models in \texttt{dismo}. The environmental data consist of 9 environmental files covering the South American continent.  



Figure~\ref{fig1} shows (A) the top variable, (B) the AUC of the top models, (C) the lookup table that is the basis of the model, and (D) the predicted distribution with the presence points plotted.  In this distribution the result is very similar to the results from GARP and MaxEnt in paper \cite{Phillips2007}.  Table~\ref{tab2} lists the results for all variables.

<<echo=FALSE, eval=TRUE, results=tex>>=
xtable(result$result,caption="These are the results", label="tab2")
@

Table~\ref{tab3} shows the AUC of these data with other algorithms in \cite{dismo}.  The same protocol was used to ensure comparability.  The models that perform best include geographic models but these are not in a split test protocol. 
 
<<echo=FALSE, eval=TRUE, results=tex>>=
compresults=fread("table.txt")
setorder(compresults,-AUC)
xtable(compresults,caption="These are the comparative results", label="tab3")
@


\subsection{World Data}

Figure~\ref{fig2} shows the Bradypus data applied to a dataset of 940 layers of world extent.  These contain many groups of variables listed in  \cite{Stockwell:2006rf} including satellite greening, monthly temperature and rainfall and many others.  They are also of different resolution ranging from x to topo data sets with resolutions.

\begin{figure}[htbp]
\begin{center}
\includegraphics{article-005.pdf}
<<fig=T,echo=F,eval=F,png=FALSE, pdf=TRUE>>=
Tfiles <- list.files(path="/home/davids99us/data/Terrestrial", 
                     pattern='pgm', full.names=TRUE )
result1=ww(Pres,Tfiles,trim=TRUE,multi=FALSE)
save(result1,file="result1.Rda")
plot.ww(result1)
@
\caption{\label{fig2} \texttt{WhyWhere} predicted distribution of using world data set.}
\end{center}
\end{figure}

Table~\ref{tab4} ists the top 5 results from the algorithm.  We note the accuracy of these top variables is higher than shown in Table~\ref{tab2}.  

<<echo=FALSE, eval=TRUE, results=tex>>=
load(file="result1.Rda")
xtable(result1$result[1:5],caption="These are the results", label="tab4")
@



\section{Conclusion and Further Work}

The WhyWhere package provides a useful approach to exploring the interaction between spatial data and point locations. The changes to the original WhyWhere method implemented in this package can bring greater utility while maintaining the verifyable increases in accuracy from the big data approach. For example, by enabling processing on cloud based data sets WhyWhere will permit analysis of data sets that were not possible before.  The  new method reduces few steps in the whole work flow of data processing by simplifying development of more complex models. The R package \texttt{WhyWhere} is a useful packages to fit, plot and test empirical species as a conjunction of response functions.  More complex logical expressions are planned, as are improvements in computational efficiency and access to cloud data.   


\bibliographystyle{plain}
\bibliography{../../library}
\end{document}